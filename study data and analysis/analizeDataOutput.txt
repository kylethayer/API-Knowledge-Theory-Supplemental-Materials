R version 3.6.0 (2019-04-26) -- "Planting of a Tree"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> setwd("C:/Users/kmthayer/OneDrive/Documents/UW/Research/API Concepts/paper/suplemental materials/study 1 data and analysis")
> # This file runs the statistical models and tests for the paper:
> #   Kyle Thayer, Sarah E. Chasins, and Amy J. Ko. 2020. 
> #   A Theory of Robust API Knowledge. ACM Trans. Comput.Educ.1, 1 (December 2020).
> 
> library(lmerTest)
Loading required package: lme4
Loading required package: Matrix

Attaching package: ‘lmerTest’

The following object is masked from ‘package:lme4’:

    lmer

The following object is masked from ‘package:stats’:

    step

Warning messages:
1: package ‘lmerTest’ was built under R version 3.6.1 
2: package ‘lme4’ was built under R version 3.6.1 
> library("pscl")
Classes and Methods for R developed in the
Political Science Computational Laboratory
Department of Political Science
Stanford University
Simon Jackman
hurdle and zeroinfl functions by Achim Zeileis
Warning message:
package ‘pscl’ was built under R version 3.6.1 
> library("lmtest")
Loading required package: zoo

Attaching package: ‘zoo’

The following objects are masked from ‘package:base’:

    as.Date, as.Date.numeric

Warning messages:
1: package ‘lmtest’ was built under R version 3.6.1 
2: package ‘zoo’ was built under R version 3.6.1 
> library(ordinal) # for clmm

Attaching package: ‘ordinal’

The following objects are masked from ‘package:lme4’:

    ranef, VarCorr

Warning message:
package ‘ordinal’ was built under R version 3.6.2 
> library(RVAideMemoire) # for Anova.clmm
*** Package RVAideMemoire v 0.9-74 ***

Attaching package: ‘RVAideMemoire’

The following object is masked from ‘package:lme4’:

    dummy

Warning message:
package ‘RVAideMemoire’ was built under R version 3.6.2 
> library(MASS) # for polr
> library(car) # for Anova for polr
Loading required package: carData
Registered S3 methods overwritten by 'car':
  method                          from
  influence.merMod                lme4
  cooks.distance.influence.merMod lme4
  dfbeta.influence.merMod         lme4
  dfbetas.influence.merMod        lme4
Warning message:
package ‘car’ was built under R version 3.6.2 
> library(plyr)
Warning message:
package ‘plyr’ was built under R version 3.6.1 
> 
> #########################################################
> ##################### Load the data #####################
> #########################################################
> 
> # To load the data files make sure to set your working directory to where these csv files are saved
> lineInfo = read.csv("lineInfo.csv",sep=",")
> taskInfo = read.csv("taskInfo.csv",sep=",")
> 
> #########################################################
> ##################### Data Cleaning #####################
> #########################################################
> 
> #simplify the names of the columns about who saw annotations that were incorrect 
> lineInfo$badOlTemplate = lineInfo$BadOLTemplate..mislabeled.projection.template.as.interaction.template.
> lineInfo$badNaturalFact = lineInfo$Bad.Natural.fact..suggested.trigrams.function.not.ngrams.function.
> 
> taskInfo$badOlTemplate = taskInfo$BadOLTemplate..mislabeled.projection.template.as.interaction.template.
> taskInfo$badNaturalFact = taskInfo$Bad.Natural.fact..suggested.trigrams.function.not.ngrams.function.
> 
> #remove tasks techincal difficulties
> lineInfo <- lineInfo[lineInfo["techDiff"] == "false", ]
> taskInfo <- taskInfo[taskInfo["techDiff"] == "FALSE", ]
> 
> # remove tasks with progress that we ignore.
> taskInfo <- taskInfo[is.na(taskInfo["Exclude..task.problem."]), ]
> 
> #-------------- Remove rarely answered code lines -------------- #
> 
> removeLessRatedLines <- function(tmpLineInfo, tmpTaskInfo, api){
+   tmpLineInfo <- tmpLineInfo[lineInfo["api"] == api,]
+   maxRatings = nrow(tmpTaskInfo)
+   lineCounts = count(lineInfo, c('line'))
+   lineCounts$lineFreq = lineCounts$freq
+   lineCounts = lineCounts[c("line", "lineFreq")]
+   
+   tmpLineInfoWithLineCounts = merge(tmpLineInfo, lineCounts, by="line")
+   tmpLineInfoWithLineCounts$maxLineCount = maxRatings
+   
+   tmpLineInfoWithLineCountsFiltered = tmpLineInfoWithLineCounts [tmpLineInfoWithLineCounts["lineFreq"] / maxRatings >= .90,]
+   tmpLineInfoWithLineCountsFiltered
+ }
> 
> 
> #naturalLineInfo <- lineInfo[lineInfo["api"] == "Natural",]
> naturalTaskInfo = taskInfo[taskInfo["api"] == 'Natural',]
> naturalLineInfo <- removeLessRatedLines(lineInfo, naturalTaskInfo, "Natural")
> 
> #d3LineInfo <- lineInfo[lineInfo["api"] == "D3",]
> d3TaskInfo = taskInfo[taskInfo["api"] == 'D3',]
> d3LineInfo <- removeLessRatedLines(lineInfo, d3TaskInfo, "D3")
> 
> #threeJSLineInfo <- lineInfo[lineInfo["api"] == "Threejs",]
> threeJSTaskInfo = taskInfo[taskInfo["api"] == 'Threejs',]
> threeJSLineInfo <- removeLessRatedLines(lineInfo, threeJSTaskInfo, "Threejs")
> 
> #openLayersLineInfo <- lineInfo[lineInfo["api"] == "OpenLayers",]
> openLayersTaskInfo = taskInfo[taskInfo["api"] == 'OpenLayers',]
> openLayersLineInfo <- removeLessRatedLines(lineInfo, openLayersTaskInfo, "OpenLayers")
> 
> #combine back together
> 
> lineInfoFiltered <- rbind(naturalLineInfo, d3LineInfo)
> lineInfoFiltered <- rbind(lineInfoFiltered, threeJSLineInfo)
> lineInfoFiltered <- rbind(lineInfoFiltered, openLayersLineInfo)
> 
> lineInfo <- lineInfoFiltered
> 
> #write.csv(lineInfo, file="lineInfoCleaned.csv")
> 
> #-------------- Fix data types -------------- #
> 
> lineInfo <- transform(lineInfo,
+                       id = as.factor(id)
+                       #,numAnTypes = as.factor(numAnTypes)
+                       #,stageNum = ordered(stageNum)
+                       ,X.LearnedPLs = ordered(X.LearnedPLs, levels=c('1', '2-4', '5-9', '10+'))
+                       ,X.LearnedAPIs = ordered(X.LearnedAPIs, levels=c('1', '2-4', '5-9', '10+'))
+                       ,debugConf = ordered(debugConf)
+ )
> 
> taskInfo <- transform(taskInfo,
+                       id = as.factor(id)
+                       #,numAnTypes = as.factor(numAnTypes)
+                       #,stageNum = ordered(stageNum)
+                       ,X.LearnedPLs = ordered(X.LearnedPLs, levels=c('1', '"2-4"', '"5-9"', '10+'))
+                       ,X.LearnedAPIs = ordered(X.LearnedAPIs, levels=c('1', '"2-4"', '"5-9"', '10+'))
+                       ,debugConf = ordered(debugConf)
+ )
> 
> 
> #########################################################
> ########## Statistical models and tests #################
> #########################################################
> 
> 
> #------------------------------------------------ #
> #-------------- Test task progress -------------- #
> #------------------------------------------------ #
> 
> 
> #-------------- task progress by API (Table 2)---- #
> 
> df1 = as.data.frame(taskInfo) # Anova.clmm fails unless we do this
> df1$X..completed..subtask.level. = factor(df1$X..completed..subtask.level.)
> for (api in c("D3", "Natural", "OpenLayers", "Threejs")){
+   api <= "D3"
+   
+   message  (paste("--- start task progress of annotation type for api",  api,  "----"))
+   
+   #recompute levels to remove unused levels
+   tmpData = df1[df1["api"] == api,]
+   tmpData$X..completed..subtask.level. = factor(tmpData$X..completed..subtask.level.)
+   
+   tmpData$X.LearnedPLs = ordered(tmpData$X.LearnedPLs)
+   tmpData$X.LearnedAPIs = ordered(tmpData$X.LearnedAPIs)
+   tmpData$debugConf = ordered(tmpData$debugConf)
+   
+   print ("X.LearnedPLs, X.LearnedAPIs, debugConf")
+   print(table(tmpData["X.LearnedPLs"]))
+   print(table(tmpData["X.LearnedAPIs"]))
+   print(table(tmpData["debugConf"]))
+   
+   
+   #run simplified version of model to get starting values
+   # the main model sometimes fails if we don't do this
+   m = polr(X..completed..subtask.level. ~ 
+              ( has.concept + has.template +  has.fact ) 
+            # + X.LearnedPLs 
+            + X.LearnedAPIs
+            # + debugConf 
+            #,data=df1[df1["api"] == api,], 
+            ,tmpData,
+            Hess=TRUE)
+   
+   start <- c(
+     coef(m), 
+     integer(
+       length(unique(tmpData$debugConf)) -1  
+       + length(unique(tmpData$X.LearnedPLs)) - 1
+     ), 
+     m$zeta
+   )
+   
+   m = polr(X..completed..subtask.level. ~ 
+              ( has.concept + has.template +  has.fact ) 
+            + X.LearnedPLs
+            + X.LearnedAPIs
+            + debugConf  
+            # + badNaturalFact #There was a mislabeled natural fact, but it never showed up as significant in any models, so we ignore it
+            ,tmpData,
+            start = start,
+            Hess=TRUE)
+   
+   
+   print(paste("N=",nrow(df1[df1["api"] == api,])) )
+   
+   # The Anova funcion doesn't work because it tries to build models and gets bad initial values
+   # and it doesn't let us supply better starting values, so we calculate p-values manually:
+   #Anova(m) #fails :(
+ 
+   degrees_of_freedom <- m$n - length(coef(m)) - length(m$zeta)
+   
+   m_summary <- summary(m)
+   
+   t_values <- m_summary[["coefficients"]][, "t value"]
+   
+   p_values <- 2*pt(-abs(t_values), degrees_of_freedom)
+   
+   m_summary[["coefficients"]] <- cbind(m_summary[["coefficients"]], p_values)
+   
+   print(m_summary)
+   
+   message (paste("--- end task progress of api",  api, "----"))
+   message  ()
+ }
--- start task progress of annotation type for api D3 ----
[1] "X.LearnedPLs, X.LearnedAPIs, debugConf"

"2-4" "5-9"   10+ 
   12    22     3 

    1 "2-4" "5-9"   10+ 
    4    11    15     7 

 1  2  3  4  5  6 
 2  3  6 14  5  7 
[1] "N= 37"
Call:
polr(formula = X..completed..subtask.level. ~ (has.concept + 
    has.template + has.fact) + X.LearnedPLs + X.LearnedAPIs + 
    debugConf, data = tmpData, start = start, Hess = TRUE)

Coefficients:
                   Value Std. Error t value p_values
has.conceptTRUE  -2.6486     0.9806 -2.7010  0.01722
has.templateTRUE  2.0773     0.8192  2.5358  0.02376
has.factTRUE     -0.6269     0.8240 -0.7608  0.45940
X.LearnedPLs.L    0.3820     1.3369  0.2858  0.77925
X.LearnedPLs.Q    0.8999     0.7711  1.1669  0.26273
X.LearnedAPIs.L   2.4415     1.0484  2.3287  0.03537
X.LearnedAPIs.Q   0.4039     0.8345  0.4840  0.63586
X.LearnedAPIs.C   1.4544     0.7378  1.9713  0.06878
debugConf.L      -0.1375     1.1184 -0.1229  0.90391
debugConf.Q      -0.2527     1.1343 -0.2228  0.82691
debugConf.C      -1.0903     1.1414 -0.9552  0.35569
debugConf^4       2.8456     1.1641  2.4444  0.02834
debugConf^5       0.2833     0.8025  0.3530  0.72935

Intercepts:
        Value   Std. Error t value p_values
0|0.1   -4.9270  1.2224    -4.0306  0.0012 
0.1|0.2 -3.7996  1.0493    -3.6211  0.0028 
0.2|0.3 -2.8124  0.9493    -2.9625  0.0103 
0.3|0.4 -1.5679  0.8607    -1.8215  0.0900 
0.4|0.5 -1.1867  0.8313    -1.4276  0.1753 
0.5|1.1 -0.4822  0.7912    -0.6095  0.5519 
1.1|1.2  0.0884  0.7914     0.1117  0.9126 
1.2|1.3  0.9700  0.8319     1.1661  0.2631 
1.3|1.4  3.6405  1.1870     3.0670  0.0084 
1.4|3.1  4.6554  1.4098     3.3021  0.0052 

Residual Deviance: 138.3794 
AIC: 184.3794 
--- end task progress of api D3 ----

--- start task progress of annotation type for api Natural ----
[1] "X.LearnedPLs, X.LearnedAPIs, debugConf"

"2-4" "5-9"   10+ 
   18    33     3 

    1 "2-4" "5-9"   10+ 
    6    17    19    12 

 1  2  3  4  5  6 
 3  3 12 19  7 10 
[1] "N= 54"
Call:
polr(formula = X..completed..subtask.level. ~ (has.concept + 
    has.template + has.fact) + X.LearnedPLs + X.LearnedAPIs + 
    debugConf, data = tmpData, start = start, Hess = TRUE)

Coefficients:
                   Value Std. Error t value p_values
has.conceptTRUE   0.2951     0.7764  0.3801 0.706234
has.templateTRUE  2.2761     0.7930  2.8703 0.007005
has.factTRUE     -2.2599     0.8525 -2.6511 0.012096
X.LearnedPLs.L    0.7083     1.2304  0.5757 0.568622
X.LearnedPLs.Q   -0.4706     0.7431 -0.6333 0.530761
X.LearnedAPIs.L   0.2591     0.8308  0.3119 0.757003
X.LearnedAPIs.Q  -0.6393     0.6220 -1.0277 0.311358
X.LearnedAPIs.C   1.0978     0.5928  1.8519 0.072742
debugConf.L       0.1533     1.0335  0.1484 0.882918
debugConf.Q      -0.3766     0.9003 -0.4183 0.678351
debugConf.C      -2.5321     1.1342 -2.2324 0.032279
debugConf^4       0.7785     0.9569  0.8136 0.421553
debugConf^5      -0.5448     0.7367 -0.7396 0.464637

Intercepts:
        Value   Std. Error t value p_values
0|0.1   -0.3641  0.7051    -0.5164  0.6089 
0.1|0.2 -0.2523  0.7063    -0.3572  0.7232 
0.2|1    0.2003  0.7101     0.2821  0.7796 
1|1.1    3.2438  0.8493     3.8195  0.0005 
1.1|1.3  3.7377  0.9064     4.1235  0.0002 
1.3|1.4  4.5935  1.0549     4.3546  0.0001 
1.4|1.6  5.4350  1.2802     4.2454  0.0002 

Residual Deviance: 125.1682 
AIC: 165.1682 
--- end task progress of api Natural ----

--- start task progress of annotation type for api OpenLayers ----
[1] "X.LearnedPLs, X.LearnedAPIs, debugConf"

"2-4" "5-9"   10+ 
   18    31     3 

    1 "2-4" "5-9"   10+ 
    6    16    19    11 

 1  2  3  4  5  6 
 3  3 11 18  7 10 
[1] "N= 52"
Call:
polr(formula = X..completed..subtask.level. ~ (has.concept + 
    has.template + has.fact) + X.LearnedPLs + X.LearnedAPIs + 
    debugConf, data = tmpData, start = start, Hess = TRUE)

Coefficients:
                    Value Std. Error  t value p_values
has.conceptTRUE   0.94563     0.5863  1.61281  0.11841
has.templateTRUE -0.67890     0.5961 -1.13886  0.26477
has.factTRUE     -1.50466     0.6441 -2.33589  0.02717
X.LearnedPLs.L   -1.81378     1.0989 -1.65056  0.11041
X.LearnedPLs.Q   -0.68808     0.6600 -1.04248  0.30643
X.LearnedAPIs.L   2.21942     0.8436  2.63080  0.01390
X.LearnedAPIs.Q   0.97994     0.6661  1.47114  0.15281
X.LearnedAPIs.C   0.07016     0.5489  0.12781  0.89925
debugConf.L      -0.53348     0.9246 -0.57696  0.56875
debugConf.Q       0.40783     0.7878  0.51770  0.60889
debugConf.C       0.05172     0.9516  0.05435  0.95706
debugConf^4      -1.14206     0.9387 -1.21666  0.23426
debugConf^5      -0.22864     0.7094 -0.32230  0.74971

Intercepts:
        Value   Std. Error t value p_values
0|0.1   -2.9117  0.7592    -3.8353  0.0007 
0.1|1   -2.7112  0.7410    -3.6587  0.0011 
1|1.1   -1.5397  0.6702    -2.2972  0.0296 
1.1|2   -1.1889  0.6565    -1.8108  0.0813 
2|2.3   -0.8623  0.6437    -1.3396  0.1915 
2.3|2.4 -0.7616  0.6403    -1.1896  0.2446 
2.4|2.5 -0.4822  0.6316    -0.7634  0.4518 
2.5|2.6 -0.3017  0.6278    -0.4806  0.6347 
2.6|2.7  0.1475  0.6255     0.2357  0.8154 
2.7|3    0.4334  0.6252     0.6932  0.4941 
3|3.3    2.5780  0.7629     3.3791  0.0022 
3.3|3.7  2.9831  0.8274     3.6052  0.0012 

Residual Deviance: 218.0034 
AIC: 268.0034 
--- end task progress of api OpenLayers ----

--- start task progress of annotation type for api Threejs ----
[1] "X.LearnedPLs, X.LearnedAPIs, debugConf"

"2-4" "5-9"   10+ 
   17    32     3 

    1 "2-4" "5-9"   10+ 
    5    17    18    12 

 1  2  3  4  5  6 
 2  3 12 18  7 10 
[1] "N= 52"
Call:
polr(formula = X..completed..subtask.level. ~ (has.concept + 
    has.template + has.fact) + X.LearnedPLs + X.LearnedAPIs + 
    debugConf, data = tmpData, start = start, Hess = TRUE)

Coefficients:
                    Value Std. Error  t value p_values
has.conceptTRUE   1.23265     0.6151  2.00407  0.05601
has.templateTRUE  0.04560     0.6282  0.07259  0.94271
has.factTRUE      0.78729     0.6238  1.26211  0.21856
X.LearnedPLs.L   17.96831   119.4499  0.15043  0.88164
X.LearnedPLs.Q    9.82288    68.9650  0.14243  0.88788
X.LearnedAPIs.L   0.75160     0.7793  0.96447  0.34405
X.LearnedAPIs.Q  -0.40356     0.6566 -0.61466  0.54434
X.LearnedAPIs.C  -0.08571     0.5719 -0.14987  0.88207
debugConf.L      -0.26800     1.0733 -0.24970  0.80486
debugConf.Q       0.50261     1.0277  0.48905  0.62907
debugConf.C      -0.55777     0.9899 -0.56348  0.57813
debugConf^4      -0.16703     0.9359 -0.17847  0.85979
debugConf^5      -0.02060     0.6915 -0.02978  0.97648

Intercepts:
        Value    Std. Error t value  p_values
0|0.2   -11.5189  56.3188    -0.2045   0.8396
0.2|0.3 -10.3676  56.3129    -0.1841   0.8554
0.3|0.4  -9.7912  56.3117    -0.1739   0.8634
0.4|0.5  -9.5735  56.3114    -0.1700   0.8664
0.5|0.6  -8.1512  56.3106    -0.1448   0.8861
0.6|0.7  -6.0920  56.3114    -0.1082   0.9147
0.7|0.8  -5.5616  56.3116    -0.0988   0.9221
0.8|1    -5.4155  56.3117    -0.0962   0.9242
1|1.2    -5.0712  56.3119    -0.0901   0.9290
1.2|1.3  -4.8695  56.3120    -0.0865   0.9318
1.3|1.4  -3.5418  56.3129    -0.0629   0.9504
1.4|2.2  -2.7679  56.3143    -0.0492   0.9612
2.2|2.3   6.9270  89.1209     0.0777   0.9387
2.3|2.4  16.6720 112.6162     0.1480   0.8835

Residual Deviance: 183.2397 
AIC: 237.2397 
--- end task progress of api Threejs ----

Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 

> #-------------- numAnTypes (Table 3) -------------- #
> df1$numAnTypes = factor(df1$numAnTypes)
> for (api in c("D3", "Natural", "OpenLayers", "Threejs")){
+   
+   message  (paste("--- start task progress by annotation count for api",  api,  "----"))
+   
+   #recompute levels to remove unused levels
+   tmpData = df1[df1["api"] == api,]
+   tmpData$X..completed..subtask.level. = factor(tmpData$X..completed..subtask.level.)
+   
+   tmpData$X.LearnedPLs = ordered(tmpData$X.LearnedPLs)
+   tmpData$X.LearnedAPIs = ordered(tmpData$X.LearnedAPIs)
+   tmpData$debugConf = ordered(tmpData$debugConf)
+   
+   print ("X.LearnedPLs, X.LearnedAPIs, debugConf")
+   print(table(tmpData["X.LearnedPLs"]))
+   print(table(tmpData["X.LearnedAPIs"]))
+   print(table(tmpData["debugConf"]))
+   
+   m = polr(X..completed..subtask.level. ~ 
+              numAnTypes
+            #  + X.LearnedPLs
+            # + X.LearnedAPIs 
+             + debugConf 
+            ,tmpData,
+            Hess=TRUE)
+   
+   start <- c(
+     coef(m), 
+     integer(
+       + length(unique(tmpData$X.LearnedAPIs)) -1  
+       + length(unique(tmpData$X.LearnedPLs)) - 1
+     ) + 0.5, 
+     m$zeta
+   )
+   
+   m = polr(X..completed..subtask.level. ~ 
+              numAnTypes
+             + X.LearnedPLs
+             + X.LearnedAPIs 
+             + debugConf 
+             # + badNaturalFact #There was a mislabeled natural fact, but it never showed up as significant in any models, so we ignore it
+            ,tmpData,
+            start = start,
+            Hess=TRUE)
+ 
+   print(paste("N=",nrow(df1[df1["api"] == api,])) )
+   #print(summary(m))
+   
+   # The Anova funcion doesn't work because it tries to build models and gets bad initial values
+   # and it doesn't let us supply better starting values, so we calculate p-values manually
+   
+   #Anova(m) #fails :(
+   
+   degrees_of_freedom <- m$n - length(coef(m)) - length(m$zeta)
+   
+   m_summary <- summary(m)
+   
+   t_values <- m_summary[["coefficients"]][, "t value"]
+   
+   p_values <- 2*pt(-abs(t_values), degrees_of_freedom)
+   
+   m_summary[["coefficients"]] <- cbind(m_summary[["coefficients"]], p_values)
+   
+   print(m_summary)
+   
+   
+   #print(Anova(m, type=3))
+   message (paste("--- end task progress of api",  api, "----"))
+   message  ()
+ }
--- start task progress by annotation count for api D3 ----
[1] "X.LearnedPLs, X.LearnedAPIs, debugConf"

"2-4" "5-9"   10+ 
   12    22     3 

    1 "2-4" "5-9"   10+ 
    4    11    15     7 

 1  2  3  4  5  6 
 2  3  6 14  5  7 
[1] "N= 37"
Call:
polr(formula = X..completed..subtask.level. ~ numAnTypes + X.LearnedPLs + 
    X.LearnedAPIs + debugConf, data = tmpData, start = start, 
    Hess = TRUE)

Coefficients:
                   Value Std. Error  t value p_values
numAnTypes1      0.07579     1.1186  0.06775  0.94694
numAnTypes2      0.07600     0.9838  0.07725  0.93952
numAnTypes3     -0.56606     1.0230 -0.55336  0.58875
X.LearnedPLs.L  -0.79526     1.2383 -0.64223  0.53110
X.LearnedPLs.Q   1.02244     0.8060  1.26859  0.22528
X.LearnedAPIs.L  2.30700     1.0587  2.17903  0.04691
X.LearnedAPIs.Q  0.56152     0.8695  0.64579  0.52886
X.LearnedAPIs.C  1.54283     0.7883  1.95726  0.07056
debugConf.L     -0.30867     1.0035 -0.30758  0.76293
debugConf.Q      0.37516     0.9856  0.38064  0.70919
debugConf.C     -1.93058     1.0512 -1.83654  0.08760
debugConf^4      1.64146     1.0795  1.52064  0.15061
debugConf^5      0.43800     0.8375  0.52301  0.60914

Intercepts:
        Value   Std. Error t value p_values
0|0.1   -3.7284  1.1233    -3.3190  0.0051 
0.1|0.2 -2.5630  0.9762    -2.6256  0.0200 
0.2|0.3 -1.5983  0.9102    -1.7560  0.1009 
0.3|0.4 -0.5759  0.8639    -0.6666  0.5159 
0.4|0.5 -0.3002  0.8519    -0.3524  0.7298 
0.5|1.1  0.2495  0.8375     0.2980  0.7701 
1.1|1.2  0.7094  0.8445     0.8400  0.4150 
1.2|1.3  1.4453  0.8773     1.6475  0.1217 
1.3|1.4  3.6866  1.1931     3.0898  0.0080 
1.4|3.1  4.5433  1.4046     3.2346  0.0060 

Residual Deviance: 147.767 
AIC: 193.767 
--- end task progress of api D3 ----

--- start task progress by annotation count for api Natural ----
[1] "X.LearnedPLs, X.LearnedAPIs, debugConf"

"2-4" "5-9"   10+ 
   18    33     3 

    1 "2-4" "5-9"   10+ 
    6    17    19    12 

 1  2  3  4  5  6 
 3  3 12 19  7 10 
[1] "N= 54"
Call:
polr(formula = X..completed..subtask.level. ~ numAnTypes + X.LearnedPLs + 
    X.LearnedAPIs + debugConf, data = tmpData, start = start, 
    Hess = TRUE)

Coefficients:
                   Value Std. Error  t value p_values
numAnTypes1      0.08132     0.8265  0.09839  0.92220
numAnTypes2     -1.13895     0.8449 -1.34796  0.18658
numAnTypes3      0.69104     0.8172  0.84564  0.40367
X.LearnedPLs.L   0.60403     1.3010  0.46428  0.64541
X.LearnedPLs.Q  -0.66359     0.7976 -0.83194  0.41125
X.LearnedAPIs.L  0.67348     0.7757  0.86823  0.39136
X.LearnedAPIs.Q -0.60053     0.6044 -0.99360  0.32743
X.LearnedAPIs.C  0.81282     0.5872  1.38412  0.17534
debugConf.L     -0.33151     0.9880 -0.33552  0.73929
debugConf.Q      0.37857     0.8626  0.43885  0.66355
debugConf.C     -2.24890     1.1053 -2.03457  0.04975
debugConf^4      1.39996     0.9675  1.44699  0.15706
debugConf^5     -0.83451     0.7351 -1.13518  0.26424

Intercepts:
        Value   Std. Error t value p_values
0|0.1   -0.4966  0.7783    -0.6380  0.5277 
0.1|0.2 -0.4020  0.7785    -0.5163  0.6090 
0.2|1   -0.0053  0.7790    -0.0068  0.9946 
1|1.1    2.8799  0.9046     3.1836  0.0031 
1.1|1.3  3.3776  0.9627     3.5085  0.0013 
1.3|1.4  4.1887  1.1056     3.7887  0.0006 
1.4|1.6  4.9249  1.3191     3.7336  0.0007 

Residual Deviance: 133.6264 
AIC: 173.6264 
--- end task progress of api Natural ----

--- start task progress by annotation count for api OpenLayers ----
[1] "X.LearnedPLs, X.LearnedAPIs, debugConf"

"2-4" "5-9"   10+ 
   18    31     3 

    1 "2-4" "5-9"   10+ 
    6    16    19    11 

 1  2  3  4  5  6 
 3  3 11 18  7 10 
[1] "N= 52"
Call:
polr(formula = X..completed..subtask.level. ~ numAnTypes + X.LearnedPLs + 
    X.LearnedAPIs + debugConf, data = tmpData, start = start, 
    Hess = TRUE)

Coefficients:
                    Value Std. Error  t value p_values
numAnTypes1     -1.849271     0.7764 -2.38199  0.02453
numAnTypes2     -0.486438     0.8263 -0.58871  0.56095
numAnTypes3     -1.559457     0.8348 -1.86796  0.07266
X.LearnedPLs.L  -1.091369     1.2316 -0.88612  0.38338
X.LearnedPLs.Q  -0.606188     0.7697 -0.78752  0.43784
X.LearnedAPIs.L  2.314266     0.8554  2.70551  0.01167
X.LearnedAPIs.Q  0.034477     0.6528  0.05282  0.95827
X.LearnedAPIs.C -0.007408     0.5607 -0.01321  0.98956
debugConf.L      0.048552     0.8873  0.05472  0.95677
debugConf.Q      0.801844     0.7588  1.05675  0.29999
debugConf.C     -0.787756     1.0079 -0.78160  0.44125
debugConf^4     -0.494591     0.9564 -0.51714  0.60927
debugConf^5     -0.280403     0.7165 -0.39137  0.69859

Intercepts:
        Value   Std. Error t value p_values
0|0.1   -3.0140  0.8466    -3.5600  0.0014 
0.1|1   -2.8236  0.8335    -3.3876  0.0022 
1|1.1   -1.7247  0.7866    -2.1927  0.0371 
1.1|2   -1.4004  0.7781    -1.7998  0.0831 
2|2.3   -1.0876  0.7692    -1.4138  0.1688 
2.3|2.4 -0.9847  0.7662    -1.2852  0.2096 
2.4|2.5 -0.6774  0.7555    -0.8966  0.3778 
2.5|2.6 -0.4770  0.7510    -0.6352  0.5307 
2.6|2.7 -0.0083  0.7506    -0.0111  0.9913 
2.7|3    0.2784  0.7509     0.3708  0.7137 
3|3.3    2.4227  0.8486     2.8548  0.0082 
3.3|3.7  2.8137  0.9021     3.1191  0.0043 

Residual Deviance: 219.5118 
AIC: 269.5118 
--- end task progress of api OpenLayers ----

--- start task progress by annotation count for api Threejs ----
[1] "X.LearnedPLs, X.LearnedAPIs, debugConf"

"2-4" "5-9"   10+ 
   17    32     3 

    1 "2-4" "5-9"   10+ 
    5    17    18    12 

 1  2  3  4  5  6 
 2  3 12 18  7 10 
[1] "N= 52"
Call:
polr(formula = X..completed..subtask.level. ~ numAnTypes + X.LearnedPLs + 
    X.LearnedAPIs + debugConf, data = tmpData, start = start, 
    Hess = TRUE)

Coefficients:
                   Value Std. Error  t value p_values
numAnTypes1      0.48796     0.7997  0.61015  0.54727
numAnTypes2      0.95115     0.8161  1.16544  0.25484
numAnTypes3      2.20194     0.8686  2.53518  0.01787
X.LearnedPLs.L  16.97861    83.5414  0.20324  0.84060
X.LearnedPLs.Q   9.21497    48.2336  0.19105  0.85003
X.LearnedAPIs.L  0.68583     0.7987  0.85863  0.39870
X.LearnedAPIs.Q -0.63818     0.6289 -1.01472  0.31996
X.LearnedAPIs.C  0.13115     0.5580  0.23504  0.81609
debugConf.L     -0.01452     1.0734 -0.01353  0.98931
debugConf.Q      0.43290     1.0287  0.42082  0.67748
debugConf.C     -0.76670     0.9935 -0.77168  0.44754
debugConf^4     -0.16135     0.9215 -0.17509  0.86242
debugConf^5     -0.14570     0.6781 -0.21486  0.83162

Intercepts:
        Value    Std. Error t value  p_values
0|0.2   -11.0685  39.3969    -0.2809   0.7811
0.2|0.3  -9.9144  39.3883    -0.2517   0.8033
0.3|0.4  -9.3292  39.3865    -0.2369   0.8147
0.4|0.5  -9.1078  39.3859    -0.2312   0.8190
0.5|0.6  -7.7099  39.3848    -0.1958   0.8464
0.6|0.7  -5.7124  39.3858    -0.1450   0.8858
0.7|0.8  -5.1802  39.3861    -0.1315   0.8964
0.8|1    -5.0289  39.3863    -0.1277   0.8994
1|1.2    -4.6794  39.3866    -0.1188   0.9064
1.2|1.3  -4.4806  39.3868    -0.1138   0.9103
1.3|1.4  -3.1531  39.3883    -0.0801   0.9368
1.4|2.2  -2.3630  39.3905    -0.0600   0.9526
2.2|2.3   6.6824  62.4247     0.1070   0.9156
2.3|2.4  15.7434  78.7607     0.1999   0.8432

Residual Deviance: 184.1342 
AIC: 238.1342 
--- end task progress of api Threejs ----



> 


> #-------------- Task progress for specific examples (Table 4) ----------- #
> 
> 
> #### Check specific example of Natrual users making progress on step 1 (ngram) given that they have
> #### . This demonstrates that templates were helpful for this task (and facts were not, even when accounting for bad fact)
> naturalTaskInfo = taskInfo[taskInfo["api"] == 'Natural',]
> 
> naturalTaskInfo$X.LearnedPLs = ordered(naturalTaskInfo$X.LearnedPLs)
> naturalTaskInfo$X.LearnedAPIs = ordered(naturalTaskInfo$X.LearnedAPIs)
> naturalTaskInfo$debugConf = ordered(naturalTaskInfo$debugConf)
> 
> 
> m = glm((X..completed..subtask.level. > 0) ~
+           has.concept + has.template +  has.fact
+         + X.LearnedPLs 
+         + X.LearnedAPIs 
+         # + badNaturalFact #There was a mislabeled natural fact, but it never showed up as significant in any models, so we ignore it
+         + debugConf 
+         ,data=naturalTaskInfo, 
+         family=binomial)
> print(paste("N=",nrow(naturalTaskInfo)) )
[1] "N= 54"
> summary(m)

Call:
glm(formula = (X..completed..subtask.level. > 0) ~ has.concept + 
    has.template + has.fact + X.LearnedPLs + X.LearnedAPIs + 
    debugConf, family = binomial, data = naturalTaskInfo)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.2327  -0.4741   0.2453   0.5849   1.7206  

Coefficients:
                 Estimate Std. Error z value Pr(>|z|)   
(Intercept)      -0.22119    1.28339  -0.172  0.86317   
has.conceptTRUE   0.05388    1.02471   0.053  0.95807   
has.templateTRUE  3.45080    1.25890   2.741  0.00612 **
has.factTRUE     -3.90626    1.35841  -2.876  0.00403 **
X.LearnedPLs.L   -2.27557    2.47983  -0.918  0.35881   
X.LearnedPLs.Q   -2.29873    1.50373  -1.529  0.12634   
X.LearnedAPIs.L  -0.09985    1.36060  -0.073  0.94150   
X.LearnedAPIs.Q   0.50667    0.92602   0.547  0.58427   
X.LearnedAPIs.C   1.31590    0.88028   1.495  0.13495   
debugConf.L       0.43375    1.28703   0.337  0.73611   
debugConf.Q      -1.28938    1.10973  -1.162  0.24528   
debugConf.C      -2.05598    1.49369  -1.376  0.16868   
debugConf^4       0.08996    1.33800   0.067  0.94639   
debugConf^5       0.51048    0.95459   0.535  0.59282   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 70.047  on 53  degrees of freedom
Residual deviance: 42.173  on 40  degrees of freedom
AIC: 70.173

Number of Fisher Scoring iterations: 6

> Anova(m, type=3)
Analysis of Deviance Table (Type III tests)

Response: (X..completed..subtask.level. > 0)
              LR Chisq Df Pr(>Chisq)    
has.concept     0.0028  1  0.9580956    
has.template   11.6610  1  0.0006382 ***
has.fact       14.0971  1  0.0001736 ***
X.LearnedPLs    4.0118  2  0.1345408    
X.LearnedAPIs   3.0390  3  0.3856449    
debugConf       6.0801  5  0.2985029    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> 
> #### Check specific example of Natrual users making progress on step 2 (tfidf) given that they have
> #### completed task 1 (ngram). This demonstrates that concepts were helpful for this task
> naturalTaskInfo = taskInfo[taskInfo["api"] == 'Natural',]
> naturalTaskInfoPast1 = naturalTaskInfo[naturalTaskInfo["X..completed..subtask.level."] >= 1,]
> 
> naturalTaskInfo$X.LearnedPLs = ordered(naturalTaskInfo$X.LearnedPLs)
> naturalTaskInfoPast1$X.LearnedAPIs = ordered(naturalTaskInfoPast1$X.LearnedAPIs)
> naturalTaskInfoPast1$debugConf = ordered(naturalTaskInfoPast1$debugConf)
> 
> 
> m = glm((X..completed..subtask.level. > 1) ~
+           has.concept + has.template +  has.fact
+         + X.LearnedPLs 
+         + X.LearnedAPIs 
+         # + badNaturalFact #There was a mislabeled natural fact, but it never showed up as significant in any models, so we ignore it
+         + debugConf 
+         ,data=naturalTaskInfoPast1, 
+         family=binomial)
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 
> print(paste("N=",nrow(naturalTaskInfoPast1)) )
[1] "N= 30"
> summary(m)

Call:
glm(formula = (X..completed..subtask.level. > 1) ~ has.concept + 
    has.template + has.fact + X.LearnedPLs + X.LearnedAPIs + 
    debugConf, family = binomial, data = naturalTaskInfoPast1)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-0.90052  -0.00002   0.00000   0.00000   1.48230  

Coefficients:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)        -47.7452 56154.6256  -0.001    0.999
has.conceptTRUE     40.3252 20914.7181   0.002    0.998
has.templateTRUE    -3.7704 55743.8059   0.000    1.000
has.factTRUE        44.6461 50767.4064   0.001    0.999
X.LearnedPLs.L     133.6281 73930.4138   0.002    0.999
X.LearnedPLs.Q      -4.8914 40222.3139   0.000    1.000
X.LearnedAPIs.L     -5.1263 65002.4127   0.000    1.000
X.LearnedAPIs.Q     -9.4435 50777.9632   0.000    1.000
X.LearnedAPIs.C     12.4430 30276.4159   0.000    1.000
debugConf.L        -33.3293 44707.5336  -0.001    0.999
debugConf.Q         28.5608 39252.5095   0.001    0.999
debugConf.C          0.6119 50250.4768   0.000    1.000
debugConf^4        -51.7214 42582.7767  -0.001    0.999

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 30.0241  on 29  degrees of freedom
Residual deviance:  3.8191  on 17  degrees of freedom
AIC: 29.819

Number of Fisher Scoring iterations: 22

> Anova(m, type=3)
Analysis of Deviance Table (Type III tests)

Response: (X..completed..subtask.level. > 1)
              LR Chisq Df Pr(>Chisq)   
has.concept     3.4522  1   0.063168 . 
has.template    0.0000  1   0.999988   
has.fact        2.7726  1   0.095891 . 
X.LearnedPLs    9.8898  2   0.007119 **
X.LearnedAPIs   0.6796  3   0.877992   
debugConf      10.0439  4   0.039695 * 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Warning messages:
1: glm.fit: fitted probabilities numerically 0 or 1 occurred 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
3: glm.fit: fitted probabilities numerically 0 or 1 occurred 
4: glm.fit: fitted probabilities numerically 0 or 1 occurred 
5: glm.fit: fitted probabilities numerically 0 or 1 occurred 
6: glm.fit: fitted probabilities numerically 0 or 1 occurred 
> 
> 
> #### Check specific example of Openlayers users progress on task 2 (Graticule) given that they have
> #### completed task 1 (changing projection). This demonstrates that concepts were helpful for this task
> olTaskInfo = taskInfo[taskInfo["api"] == 'OpenLayers',]
> olTaskInfoPast1 = olTaskInfo[olTaskInfo["X..completed..subtask.level."] >= 1,]
> 
> olTaskInfoPast1$X.LearnedPLs = ordered(olTaskInfoPast1$X.LearnedPLs)
> olTaskInfoPast1$X.LearnedAPIs = ordered(olTaskInfoPast1$X.LearnedAPIs)
> olTaskInfoPast1$debugConf = ordered(olTaskInfoPast1$debugConf)
> 
> 
> # full model
> m = glm((X..completed..subtask.level. > 1) ~
+           has.concept + has.template +  has.fact
+         + X.LearnedPLs 
+         + X.LearnedAPIs 
+         + debugConf 
+         ,data=olTaskInfoPast1, 
+         family=binomial)
> print(paste("N=",nrow(olTaskInfoPast1)) )
[1] "N= 45"
> summary(m)

Call:
glm(formula = (X..completed..subtask.level. > 1) ~ has.concept + 
    has.template + has.fact + X.LearnedPLs + X.LearnedAPIs + 
    debugConf, family = binomial, data = olTaskInfoPast1)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.70427   0.00004   0.17176   0.43995   1.55920  

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)  
(Intercept)         2.7962  1264.5494   0.002   0.9982  
has.conceptTRUE     4.0672     1.8356   2.216   0.0267 *
has.templateTRUE   -1.3396     1.2585  -1.064   0.2871  
has.factTRUE       -0.9287     1.2443  -0.746   0.4554  
X.LearnedPLs.L    -13.3739  2310.3455  -0.006   0.9954  
X.LearnedPLs.Q     -8.1644  1333.8787  -0.006   0.9951  
X.LearnedAPIs.L    11.7304  2191.7860   0.005   0.9957  
X.LearnedAPIs.Q    10.2633  1633.6611   0.006   0.9950  
X.LearnedAPIs.C     3.0896   730.5961   0.004   0.9966  
debugConf.L       -11.8656  4427.9220  -0.003   0.9979  
debugConf.Q        10.3624  4042.1214   0.003   0.9980  
debugConf.C        -5.1779  2761.2949  -0.002   0.9985  
debugConf^4         3.9028  1400.2326   0.003   0.9978  
debugConf^5        -1.5967   466.7458  -0.003   0.9973  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 42.121  on 44  degrees of freedom
Residual deviance: 25.545  on 31  degrees of freedom
AIC: 53.545

Number of Fisher Scoring iterations: 18

> Anova(m, type=3)
Analysis of Deviance Table (Type III tests)

Response: (X..completed..subtask.level. > 1)
              LR Chisq Df Pr(>Chisq)   
has.concept     8.6769  1   0.003223 **
has.template    1.2029  1   0.272742   
has.fact        0.5818  1   0.445620   
X.LearnedPLs    2.8421  2   0.241466   
X.LearnedAPIs   4.6841  3   0.196446   
debugConf       3.8080  5   0.577383   
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> 
> 
> #### Check specific example of Threejs users making progress on step 0.5 
> #### which generally requires them to use the Torus command
> 
> threejsTaskInfo = taskInfo[taskInfo["api"] == 'Threejs',]
> threejsTaskInfoAddsObject = threejsTaskInfo[threejsTaskInfo["TorusGeometry.given.object"] != "N/A",]
> 
> threejsTaskInfoAddsObject$X.LearnedPLs = ordered(threejsTaskInfoAddsObject$X.LearnedPLs)
> threejsTaskInfoAddsObject$X.LearnedAPIs = ordered(threejsTaskInfoAddsObject$X.LearnedAPIs)
> threejsTaskInfoAddsObject$debugConf = ordered(threejsTaskInfoAddsObject$debugConf)
> 
> 
> m = glm((TorusGeometry.given.object) ~
+           has.concept + has.template +  has.fact
+         + X.LearnedPLs 
+         + X.LearnedAPIs 
+         + debugConf 
+         ,data=threejsTaskInfoAddsObject, 
+         family=binomial)
> print(paste("N=",nrow(threejsTaskInfoAddsObject)) )
[1] "N= 47"
> summary(m)

Call:
glm(formula = (TorusGeometry.given.object) ~ has.concept + has.template + 
    has.fact + X.LearnedPLs + X.LearnedAPIs + debugConf, family = binomial, 
    data = threejsTaskInfoAddsObject)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-3.03421   0.00006   0.23903   0.57317   1.18488  

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)  
(Intercept)         5.1186   973.1370   0.005   0.9958  
has.conceptTRUE     2.6492     1.3107   2.021   0.0433 *
has.templateTRUE    0.5532     1.2938   0.428   0.6689  
has.factTRUE        0.8511     1.1362   0.749   0.4538  
X.LearnedPLs.L     13.8661  2064.3350   0.007   0.9946  
X.LearnedPLs.Q      8.0249  1191.8449   0.007   0.9946  
X.LearnedAPIs.L     2.0533     1.2788   1.606   0.1084  
X.LearnedAPIs.Q    -1.8789     1.2088  -1.554   0.1201  
X.LearnedAPIs.C     1.2942     1.0472   1.236   0.2165  
debugConf.L         2.3126     1.8256   1.267   0.2053  
debugConf.Q        -0.6014     1.6338  -0.368   0.7128  
debugConf.C        -0.5897     1.8391  -0.321   0.7485  
debugConf^4         1.3624     1.8991   0.717   0.4731  
debugConf^5        -1.7368     1.2800  -1.357   0.1748  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 51.147  on 46  degrees of freedom
Residual deviance: 33.431  on 33  degrees of freedom
AIC: 61.431

Number of Fisher Scoring iterations: 17

> Anova(m, type=3)
Analysis of Deviance Table (Type III tests)

Response: (TorusGeometry.given.object)
              LR Chisq Df Pr(>Chisq)  
has.concept     5.3892  1    0.02026 *
has.template    0.1825  1    0.66925  
has.fact        0.5939  1    0.44090  
X.LearnedPLs    3.5124  2    0.17270  
X.LearnedAPIs   4.5992  3    0.20361  
debugConf       3.7472  5    0.58635  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
> 
> 
> #### Check specific example of Threejs users making progress on step 0.6 
> #### which generally requires them to use the parameters of the Torus command correctly
> 
> threejsTaskInfo = taskInfo[taskInfo["api"] == 'Threejs',]
> threejsTaskInfoAddsTorus = threejsTaskInfo[threejsTaskInfo["X4th.param.correct.given.TorusGeometry"] != "N/A",]
> 
> threejsTaskInfoAddsTorus$X.LearnedPLs = ordered(threejsTaskInfoAddsTorus$X.LearnedPLs)
> threejsTaskInfoAddsTorus$X.LearnedAPIs = ordered(threejsTaskInfoAddsTorus$X.LearnedAPIs)
> threejsTaskInfoAddsTorus$debugConf = ordered(threejsTaskInfoAddsTorus$debugConf)
> 
> m = glm((X4th.param.correct.given.TorusGeometry) ~
+           has.concept + has.template +  has.fact
+         + X.LearnedPLs 
+         + X.LearnedAPIs 
+         + debugConf 
+         ,data=threejsTaskInfoAddsTorus, 
+         family=binomial)
Warning message:
glm.fit: fitted probabilities numerically 0 or 1 occurred 
> print(paste("N=",nrow(threejsTaskInfoAddsTorus)) )
[1] "N= 36"
> summary(m)

Call:
glm(formula = (X4th.param.correct.given.TorusGeometry) ~ has.concept + 
    has.template + has.fact + X.LearnedPLs + X.LearnedAPIs + 
    debugConf, family = binomial, data = threejsTaskInfoAddsTorus)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.86143  -0.00005   0.00000   0.00001   1.68615  

Coefficients:
                   Estimate Std. Error z value Pr(>|z|)
(Intercept)       3.770e+00  1.186e+07   0.000    1.000
has.conceptTRUE  -1.020e+00  2.023e+00  -0.504    0.614
has.templateTRUE -5.898e+01  1.498e+04  -0.004    0.997
has.factTRUE      8.187e+01  1.784e+04   0.005    0.996
X.LearnedPLs.L    4.661e+01  4.010e+04   0.001    0.999
X.LearnedPLs.Q    2.674e+01  2.315e+04   0.001    0.999
X.LearnedAPIs.L  -4.542e+01  3.183e+07   0.000    1.000
X.LearnedAPIs.Q  -9.896e-01  2.373e+07   0.000    1.000
X.LearnedAPIs.C  -8.053e-02  1.061e+07   0.000    1.000
debugConf.L      -9.817e+00  3.134e+04   0.000    1.000
debugConf.Q       5.135e+00  2.698e+04   0.000    1.000
debugConf.C      -3.776e+01  2.436e+04  -0.002    0.999
debugConf^4       2.416e+01  1.979e+04   0.001    0.999
debugConf^5      -1.691e+01  1.019e+04  -0.002    0.999

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 48.9019  on 35  degrees of freedom
Residual deviance:  9.9062  on 22  degrees of freedom
AIC: 37.906

Number of Fisher Scoring iterations: 21

> Anova(m, type=3)
Analysis of Deviance Table (Type III tests)

Response: (X4th.param.correct.given.TorusGeometry)
              LR Chisq Df Pr(>Chisq)    
has.concept     0.2561  1   0.612780    
has.template    8.4623  1   0.003626 ** 
has.fact       30.4018  1  3.512e-08 ***
X.LearnedPLs    9.6073  2   0.008200 ** 
X.LearnedAPIs   3.3272  3   0.343878    
debugConf       7.8567  5   0.164312    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Warning messages:
1: glm.fit: fitted probabilities numerically 0 or 1 occurred 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
3: glm.fit: fitted probabilities numerically 0 or 1 occurred 
4: glm.fit: fitted probabilities numerically 0 or 1 occurred 
5: glm.fit: fitted probabilities numerically 0 or 1 occurred 
6: glm.fit: fitted probabilities numerically 0 or 1 occurred 

> #------------------------------------------------ #
> #-------------- Test Undersstanding ------------- #
> #------------------------------------------------ #
> 
> 
> lineInfo$understand = factor(lineInfo$understand)
> 
> #-------- Understanding by annotation type (Table 5) ------- #
> 
> lineInfo$numAnTypes = factor(lineInfo$numAnTypes)
> df2 = as.data.frame(lineInfo)
> for (api in c("D3", "Natural", "OpenLayers", "Threejs")){
+   message  (paste("--- start understanding of lines by annotation type for api",  api,  "----"))
+   
+   m = clmm(understand ~
+              (has.concept + has.template +  has.fact)
+            + X.LearnedPLs + X.LearnedAPIs + debugConf
+            #  + badOlTemplate + badNaturalFact #There was a mislabeled natural fact and OpenLayers template, but they never showed up as significant in any models, so we ignore it
+            + (1 | line)
+            , data=df2[df2["api"] == api,])
+   
+   print(paste("N=",nrow(df2[df2["api"] == api,])) )
+   print(summary(m))
+   print(Anova.clmm(m, type=3))
+   message (paste("--- end task understanding of api",  api, "----"))
+   message  ()
+ }
--- start understanding of lines by annotation type for api D3 ----
[1] "N= 1391"
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: understand ~ (has.concept + has.template + has.fact) + X.LearnedPLs +  
    X.LearnedAPIs + debugConf + (1 | line)
data:    df2[df2["api"] == api, ]

 link  threshold nobs logLik   AIC     niter      max.grad cond.H 
 logit flexible  1391 -2079.87 4195.73 2574(7725) 1.54e-03 1.6e+02

Random effects:
 Groups Name        Variance Std.Dev.
 line   (Intercept) 0.6564   0.8102  
Number of groups:  line 27 

Coefficients:
                 Estimate Std. Error z value Pr(>|z|)    
has.concepttrue  -0.04204    0.12026  -0.350 0.726664    
has.templatetrue  0.35289    0.11795   2.992 0.002774 ** 
has.facttrue     -0.28486    0.11853  -2.403 0.016248 *  
X.LearnedPLs.L    0.87293    0.20597   4.238 2.25e-05 ***
X.LearnedPLs.Q   -0.02645    0.12027  -0.220 0.825914    
X.LearnedAPIs.L   0.08180    0.14660   0.558 0.576824    
X.LearnedAPIs.Q  -0.40147    0.11761  -3.414 0.000641 ***
X.LearnedAPIs.C   0.11381    0.10528   1.081 0.279677    
debugConf.L       1.22672    0.19511   6.287 3.23e-10 ***
debugConf.Q      -0.81494    0.16576  -4.916 8.81e-07 ***
debugConf.C       0.07776    0.19641   0.396 0.692161    
debugConf^4       0.46476    0.17993   2.583 0.009795 ** 
debugConf^5      -0.15432    0.13130  -1.175 0.239865    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.4410     0.2027  -7.108
2|3  -0.1308     0.1997  -0.655
3|4   0.8671     0.2006   4.323
4|5   1.7148     0.2035   8.428
Analysis of Deviance Table (Type II tests)

Response: understand
              LR Chisq Df Pr(>Chisq)    
has.concept      0.122  1   0.726713    
has.template     8.969  1   0.002747 ** 
has.fact         5.786  1   0.016159 *  
X.LearnedPLs    30.299  2  2.635e-07 ***
X.LearnedAPIs   12.642  3   0.005478 ** 
debugConf       62.156  5  4.353e-12 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
--- end task understanding of api D3 ----

--- start understanding of lines by annotation type for api Natural ----
[1] "N= 1334"
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: understand ~ (has.concept + has.template + has.fact) + X.LearnedPLs +  
    X.LearnedAPIs + debugConf + (1 | line)
data:    df2[df2["api"] == api, ]

 link  threshold nobs logLik   AIC     niter      max.grad cond.H 
 logit flexible  1334 -1847.39 3730.78 2547(7644) 1.44e-03 2.8e+02

Random effects:
 Groups Name        Variance Std.Dev.
 line   (Intercept) 1.114    1.055   
Number of groups:  line 25 

Coefficients:
                 Estimate Std. Error z value Pr(>|z|)    
has.concepttrue  -0.32713    0.13138  -2.490   0.0128 *  
has.templatetrue  0.72337    0.12732   5.681 1.34e-08 ***
has.facttrue      0.06762    0.13158   0.514   0.6073    
X.LearnedPLs.L    1.17437    0.22153   5.301 1.15e-07 ***
X.LearnedPLs.Q    0.16869    0.13083   1.289   0.1973    
X.LearnedAPIs.L  -0.14624    0.15792  -0.926   0.3544    
X.LearnedAPIs.Q   0.23714    0.12288   1.930   0.0536 .  
X.LearnedAPIs.C   0.62728    0.11167   5.617 1.94e-08 ***
debugConf.L       0.36901    0.19820   1.862   0.0626 .  
debugConf.Q       0.12587    0.16520   0.762   0.4461    
debugConf.C      -1.38501    0.20930  -6.617 3.66e-11 ***
debugConf^4       1.33555    0.19456   6.865 6.67e-12 ***
debugConf^5      -1.26320    0.14532  -8.693  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.4003     0.2541  -5.512
2|3  -0.2396     0.2524  -0.949
3|4   0.3746     0.2526   1.483
4|5   1.3324     0.2542   5.242
Analysis of Deviance Table (Type II tests)

Response: understand
              LR Chisq Df Pr(>Chisq)    
has.concept      6.236  1    0.01252 *  
has.template    32.595  1  1.135e-08 ***
has.fact         0.264  1    0.60730    
X.LearnedPLs    37.668  2  6.613e-09 ***
X.LearnedAPIs   45.195  3  8.412e-10 ***
debugConf      100.809  5  < 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
--- end task understanding of api Natural ----

--- start understanding of lines by annotation type for api OpenLayers ----
[1] "N= 1805"
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: understand ~ (has.concept + has.template + has.fact) + X.LearnedPLs +  
    X.LearnedAPIs + debugConf + (1 | line)
data:    df2[df2["api"] == api, ]

 link  threshold nobs logLik   AIC     niter       max.grad cond.H 
 logit flexible  1805 -2667.47 5370.94 2583(10336) 3.30e-03 1.3e+02

Random effects:
 Groups Name        Variance Std.Dev.
 line   (Intercept) 0.7175   0.847   
Number of groups:  line 36 

Coefficients:
                 Estimate Std. Error z value Pr(>|z|)    
has.concepttrue  -0.38643    0.10369  -3.727 0.000194 ***
has.templatetrue -0.36873    0.09913  -3.720 0.000200 ***
has.facttrue     -0.09714    0.10591  -0.917 0.359028    
X.LearnedPLs.L    0.95064    0.17593   5.403 6.54e-08 ***
X.LearnedPLs.Q    0.11102    0.10530   1.054 0.291738    
X.LearnedAPIs.L   0.37232    0.12960   2.873 0.004066 ** 
X.LearnedAPIs.Q  -0.44844    0.10416  -4.305 1.67e-05 ***
X.LearnedAPIs.C   0.66425    0.09421   7.051 1.78e-12 ***
debugConf.L       0.13516    0.15608   0.866 0.386507    
debugConf.Q      -0.45571    0.13363  -3.410 0.000649 ***
debugConf.C       0.08012    0.15600   0.514 0.607550    
debugConf^4      -0.22465    0.14485  -1.551 0.120939    
debugConf^5      -0.33422    0.11342  -2.947 0.003212 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -2.7056     0.1852 -14.608
2|3  -1.4394     0.1766  -8.149
3|4  -0.4233     0.1738  -2.435
4|5   0.8053     0.1745   4.615
Analysis of Deviance Table (Type II tests)

Response: understand
              LR Chisq Df Pr(>Chisq)    
has.concept     13.926  1  0.0001901 ***
has.template    13.878  1  0.0001951 ***
has.fact         0.841  1  0.3592181    
X.LearnedPLs    36.185  2  1.388e-08 ***
X.LearnedAPIs   63.995  3  8.227e-14 ***
debugConf       24.955  5  0.0001421 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
--- end task understanding of api OpenLayers ----

--- start understanding of lines by annotation type for api Threejs ----
[1] "N= 1927"
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: understand ~ (has.concept + has.template + has.fact) + X.LearnedPLs +  
    X.LearnedAPIs + debugConf + (1 | line)
data:    df2[df2["api"] == api, ]

 link  threshold nobs logLik   AIC     niter       max.grad cond.H 
 logit flexible  1927 -2549.50 5135.01 2846(11388) 3.17e-03 1.8e+02

Random effects:
 Groups Name        Variance Std.Dev.
 line   (Intercept) 1.184    1.088   
Number of groups:  line 38 

Coefficients:
                 Estimate Std. Error z value Pr(>|z|)    
has.concepttrue   0.46968    0.09698   4.843 1.28e-06 ***
has.templatetrue -0.20258    0.10404  -1.947 0.051523 .  
has.facttrue      0.20428    0.09786   2.087 0.036851 *  
X.LearnedPLs.L    0.96287    0.18193   5.292 1.21e-07 ***
X.LearnedPLs.Q    0.41318    0.10809   3.823 0.000132 ***
X.LearnedAPIs.L  -0.14757    0.13267  -1.112 0.266013    
X.LearnedAPIs.Q  -0.32864    0.10983  -2.992 0.002768 ** 
X.LearnedAPIs.C  -0.12503    0.09604  -1.302 0.192960    
debugConf.L       0.45260    0.16952   2.670 0.007587 ** 
debugConf.Q      -0.08542    0.15666  -0.545 0.585574    
debugConf.C       0.18192    0.16521   1.101 0.270810    
debugConf^4      -0.48247    0.15457  -3.121 0.001800 ** 
debugConf^5      -0.40817    0.11694  -3.490 0.000482 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -2.9154     0.2214 -13.170
2|3  -1.7956     0.2131  -8.426
3|4  -0.6283     0.2094  -3.001
4|5   0.4119     0.2084   1.976
Analysis of Deviance Table (Type II tests)

Response: understand
              LR Chisq Df Pr(>Chisq)    
has.concept     23.462  1  1.274e-06 ***
has.template     3.796  1   0.051378 .  
has.fact         4.361  1   0.036769 *  
X.LearnedPLs    30.011  2  3.042e-07 ***
X.LearnedAPIs   14.030  3   0.002865 ** 
debugConf       53.832  5  2.270e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
--- end task understanding of api Threejs ----

> lineInfo$numAnTypes = factor(lineInfo$numAnTypes)
> df2 = as.data.frame(lineInfo)
> for (api in c("D3", "Natural", "OpenLayers", "Threejs")){
+   message  (paste("--- start understanding of lines by annotation count for api",  api,  "----"))
+   m = clmm(understand ~
+              numAnTypes
+            + X.LearnedPLs + X.LearnedAPIs + debugConf
+            #  + badOlTemplate + badNaturalFact #There was a mislabeled natural fact and OpenLayers template, but they never showed up as significant in any models, so we ignore it
+            + (1 | line)
+            , data=df2[df2["api"] == api,])
+   
+   print(paste("N=",nrow(df2[df2["api"] == api,])) )
+   print(summary(m))
+   print(Anova.clmm(m, type=3))
+   message (paste("--- end task understanding of api",  api, "----"))
+   message  ()
+ }
--- start understanding of lines by annotation count for api D3 ----
[1] "N= 1391"
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: understand ~ numAnTypes + X.LearnedPLs + X.LearnedAPIs + debugConf +      (1 | line)
data:    df2[df2["api"] == api, ]

 link  threshold nobs logLik   AIC     niter      max.grad cond.H 
 logit flexible  1391 -2055.16 4146.31 2318(6957) 8.24e-04 1.7e+02

Random effects:
 Groups Name        Variance Std.Dev.
 line   (Intercept) 0.6797   0.8244  
Number of groups:  line 27 

Coefficients:
                Estimate Std. Error z value Pr(>|z|)    
numAnTypes1      0.17764    0.15431   1.151 0.249641    
numAnTypes2      0.89698    0.15251   5.882 4.06e-09 ***
numAnTypes3     -0.18853    0.15655  -1.204 0.228464    
X.LearnedPLs.L   0.77375    0.20239   3.823 0.000132 ***
X.LearnedPLs.Q  -0.06565    0.11997  -0.547 0.584237    
X.LearnedAPIs.L  0.13135    0.14437   0.910 0.362915    
X.LearnedAPIs.Q -0.55574    0.11910  -4.666 3.07e-06 ***
X.LearnedAPIs.C  0.24734    0.10842   2.281 0.022529 *  
debugConf.L      1.20519    0.19189   6.281 3.37e-10 ***
debugConf.Q     -0.82571    0.16403  -5.034 4.81e-07 ***
debugConf.C      0.01565    0.19554   0.080 0.936225    
debugConf^4      0.48982    0.17636   2.777 0.005479 ** 
debugConf^5     -0.18027    0.13120  -1.374 0.169446    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.2200     0.2108  -5.788
2|3   0.1215     0.2087   0.582
3|4   1.1410     0.2105   5.420
4|5   2.0079     0.2141   9.379
Analysis of Deviance Table (Type II tests)

Response: understand
              LR Chisq Df Pr(>Chisq)    
numAnTypes      61.018  3  3.562e-13 ***
X.LearnedPLs    28.905  2  5.288e-07 ***
X.LearnedAPIs   25.959  3  9.727e-06 ***
debugConf       64.911  5  1.169e-12 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
--- end task understanding of api D3 ----

--- start understanding of lines by annotation count for api Natural ----
[1] "N= 1334"
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: understand ~ numAnTypes + X.LearnedPLs + X.LearnedAPIs + debugConf +      (1 | line)
data:    df2[df2["api"] == api, ]

 link  threshold nobs logLik   AIC     niter      max.grad cond.H 
 logit flexible  1334 -1848.21 3732.42 2307(6924) 4.01e-03 3.2e+02

Random effects:
 Groups Name        Variance Std.Dev.
 line   (Intercept) 1.14     1.068   
Number of groups:  line 25 

Coefficients:
                 Estimate Std. Error z value Pr(>|z|)    
numAnTypes1      0.850289   0.161874   5.253 1.50e-07 ***
numAnTypes2      0.829342   0.155243   5.342 9.18e-08 ***
numAnTypes3      0.530697   0.158832   3.341 0.000834 ***
X.LearnedPLs.L   0.864692   0.227291   3.804 0.000142 ***
X.LearnedPLs.Q   0.009135   0.134748   0.068 0.945949    
X.LearnedAPIs.L -0.073848   0.156252  -0.473 0.636483    
X.LearnedAPIs.Q  0.416929   0.125221   3.330 0.000870 ***
X.LearnedAPIs.C  0.734964   0.114596   6.414 1.42e-10 ***
debugConf.L      0.149406   0.195763   0.763 0.445345    
debugConf.Q      0.220161   0.164406   1.339 0.180529    
debugConf.C     -1.511835   0.209747  -7.208 5.68e-13 ***
debugConf^4      1.447412   0.195174   7.416 1.21e-13 ***
debugConf^5     -1.275941   0.142741  -8.939  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -1.0534     0.2640  -3.991
2|3   0.1030     0.2632   0.391
3|4   0.7177     0.2638   2.721
4|5   1.6797     0.2663   6.308
Analysis of Deviance Table (Type II tests)

Response: understand
              LR Chisq Df Pr(>Chisq)    
numAnTypes      38.034  3  2.780e-08 ***
X.LearnedPLs    27.037  2  1.346e-06 ***
X.LearnedAPIs   59.284  3  8.360e-13 ***
debugConf      108.949  5  < 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
--- end task understanding of api Natural ----

--- start understanding of lines by annotation count for api OpenLayers ----
[1] "N= 1805"
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: understand ~ numAnTypes + X.LearnedPLs + X.LearnedAPIs + debugConf +      (1 | line)
data:    df2[df2["api"] == api, ]

 link  threshold nobs logLik   AIC     niter       max.grad cond.H 
 logit flexible  1805 -2665.42 5366.85 2897(11592) 4.46e-03 1.5e+02

Random effects:
 Groups Name        Variance Std.Dev.
 line   (Intercept) 0.7178   0.8472  
Number of groups:  line 36 

Coefficients:
                Estimate Std. Error z value Pr(>|z|)    
numAnTypes1     -0.23275    0.12916  -1.802  0.07154 .  
numAnTypes2     -0.29129    0.13100  -2.224  0.02617 *  
numAnTypes3     -0.93482    0.13484  -6.933 4.13e-12 ***
X.LearnedPLs.L   0.88796    0.17390   5.106 3.29e-07 ***
X.LearnedPLs.Q   0.15353    0.10464   1.467  0.14232    
X.LearnedAPIs.L  0.39732    0.13055   3.044  0.00234 ** 
X.LearnedAPIs.Q -0.44281    0.10488  -4.222 2.42e-05 ***
X.LearnedAPIs.C  0.58316    0.09798   5.952 2.65e-09 ***
debugConf.L      0.18608    0.15467   1.203  0.22892    
debugConf.Q     -0.43960    0.13394  -3.282  0.00103 ** 
debugConf.C     -0.01614    0.16343  -0.099  0.92132    
debugConf^4     -0.25546    0.14699  -1.738  0.08222 .  
debugConf^5     -0.31676    0.11309  -2.801  0.00509 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -2.6343     0.1898 -13.881
2|3  -1.3682     0.1815  -7.538
3|4  -0.3529     0.1789  -1.972
4|5   0.8784     0.1799   4.884
Analysis of Deviance Table (Type II tests)

Response: understand
              LR Chisq Df Pr(>Chisq)    
numAnTypes      51.598  3  3.649e-11 ***
X.LearnedPLs    31.143  2  1.728e-07 ***
X.LearnedAPIs   53.235  3  1.634e-11 ***
debugConf       23.029  5  0.0003333 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
--- end task understanding of api OpenLayers ----

--- start understanding of lines by annotation count for api Threejs ----
[1] "N= 1927"
Cumulative Link Mixed Model fitted with the Laplace approximation

formula: understand ~ numAnTypes + X.LearnedPLs + X.LearnedAPIs + debugConf +      (1 | line)
data:    df2[df2["api"] == api, ]

 link  threshold nobs logLik   AIC     niter       max.grad cond.H 
 logit flexible  1927 -2557.44 5150.89 2739(10960) 1.90e-03 2.0e+02

Random effects:
 Groups Name        Variance Std.Dev.
 line   (Intercept) 1.174    1.084   
Number of groups:  line 38 

Coefficients:
                Estimate Std. Error z value Pr(>|z|)    
numAnTypes1      0.28409    0.13410   2.118 0.034140 *  
numAnTypes2      0.30331    0.13466   2.252 0.024291 *  
numAnTypes3      0.55051    0.13107   4.200 2.67e-05 ***
X.LearnedPLs.L   0.97011    0.18186   5.334 9.59e-08 ***
X.LearnedPLs.Q   0.40186    0.10872   3.696 0.000219 ***
X.LearnedAPIs.L -0.14659    0.13658  -1.073 0.283130    
X.LearnedAPIs.Q -0.46839    0.10821  -4.329 1.50e-05 ***
X.LearnedAPIs.C -0.05853    0.09765  -0.599 0.548926    
debugConf.L      0.53970    0.17166   3.144 0.001666 ** 
debugConf.Q     -0.05495    0.15915  -0.345 0.729870    
debugConf.C      0.06739    0.16776   0.402 0.687927    
debugConf^4     -0.41078    0.15437  -2.661 0.007789 ** 
debugConf^5     -0.45041    0.11582  -3.889 0.000101 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Threshold coefficients:
    Estimate Std. Error z value
1|2  -2.8108     0.2262 -12.429
2|3  -1.6932     0.2184  -7.753
3|4  -0.5311     0.2149  -2.471
4|5   0.5035     0.2143   2.350
Analysis of Deviance Table (Type II tests)

Response: understand
              LR Chisq Df Pr(>Chisq)    
numAnTypes      17.868  3  0.0004684 ***
X.LearnedPLs    29.844  2  3.308e-07 ***
X.LearnedAPIs   23.503  3  3.171e-05 ***
debugConf       54.262  5  1.852e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
--- end task understanding of api Threejs ----

> 
> 
> 
> # optional: Find out how much the understanding of each line was influenced by the
> # different annotations. Maybe you can figure out something meaningful here.
> 
> ### Warning: VERY SLOW!!!! ###
> 
> # lineBenefitModel = clmm(understand ~
> #                           (has.concept + has.fact + has.template) * line
> #                         + X.LearnedPLs + X.LearnedAPIs + debugConf
> #                         #  + badOlTemplate + badNaturalFact
> #                         #+ (1 | stageNum)
> #                         + (1 | id)
> #                         , data=df2)
> # lineBenefitModelSummary = summary(lineBenefitModel)
> # lineBenefitModelSummary
> #
> # write out model to file to be able to analyze it
> # write.csv(as.data.frame(lineBenefitModelSummary$coef), file="lineRegressions.csv")


> 


